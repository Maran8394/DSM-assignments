{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1: What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "# Web scraping is the process of automatically extracting data from websites. It involves fetching the content of web pages and parsing it to retrieve useful information.\n",
    "\n",
    "# Why is it used?\n",
    "# - To gather large amounts of data from the web for analysis, research, or business intelligence.\n",
    "# - To monitor and collect data from websites that do not provide APIs or structured data access.\n",
    "# - To automate the extraction of data for competitive analysis, price tracking, or content aggregation.\n",
    "\n",
    "# Three areas where Web Scraping is used:\n",
    "# 1. E-commerce: To track product prices, reviews, and availability across different online stores.\n",
    "# 2. News: To aggregate news articles and updates from various sources for content curation or analysis.\n",
    "# 3. Real Estate: To collect property listings, prices, and market trends from real estate websites.\n",
    "\n",
    "# Q2: What are the different methods used for Web Scraping?\n",
    "\n",
    "# Different methods for web scraping include:\n",
    "# 1. **Manual Scraping**: Copying and pasting data from web pages manually. This is not practical for large-scale scraping.\n",
    "# 2. **Using HTML Parsing Libraries**: Libraries like Beautiful Soup or lxml are used to parse HTML content and extract data.\n",
    "# 3. **Web Scraping Frameworks**: Tools like Scrapy provide a more structured approach to scraping with features for handling requests, parsing, and storing data.\n",
    "# 4. **Browser Automation**: Tools like Selenium automate interactions with web pages and can scrape data from dynamic content generated by JavaScript.\n",
    "\n",
    "# Q3: What is Beautiful Soup? Why is it used?\n",
    "\n",
    "# Beautiful Soup is a Python library used for parsing HTML and XML documents. It provides a simple way to navigate, search, and modify the parse tree.\n",
    "\n",
    "# Why is it used?\n",
    "# - To extract data from HTML and XML documents in a more readable and manageable way.\n",
    "# - It helps handle poorly formatted or complex HTML structures, making it easier to extract the required information.\n",
    "# - It integrates well with other libraries like requests for fetching web content.\n",
    "\n",
    "# Q4: Why is Flask used in this Web Scraping project?\n",
    "\n",
    "# Flask is a lightweight web framework for Python that is used to build web applications. In a web scraping project, Flask might be used to:\n",
    "# - Create a web interface for users to input URLs or parameters for scraping.\n",
    "# - Serve the scraped data through a web application or API.\n",
    "# - Allow users to manage or view the results of scraping operations in a user-friendly manner.\n",
    "\n",
    "# Q5: Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "\n",
    "# Common AWS services used in web scraping projects:\n",
    "# 1. **Amazon EC2 (Elastic Compute Cloud)**: Provides scalable virtual servers to run web scraping scripts and applications.\n",
    "# 2. **Amazon S3 (Simple Storage Service)**: Stores and retrieves large amounts of data, such as scraped content, in a scalable and secure manner.\n",
    "# 3. **AWS Lambda**: Allows you to run code without provisioning or managing servers, which can be used for triggering scraping tasks or processing data.\n",
    "# 4. **Amazon RDS (Relational Database Service)**: Manages relational databases for storing structured data collected from web scraping.\n",
    "# 5. **Amazon CloudWatch**: Monitors and logs the performance of your AWS resources and applications, helping with debugging and performance tracking.\n",
    "\n",
    "Feel free to copy and paste this code into a single cell in your Jupyter Notebook or other Python notebook editor. If you need further assistance, just let me know!\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
